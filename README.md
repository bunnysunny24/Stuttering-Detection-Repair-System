# Stuttering Detection & Repair System

**Production-ready system for detecting and repairing stuttered speech**

Complete end-to-end pipeline for training detection models, detecting stuttering, and repairing audio.

---

## üöÄ QUICK START - COPY & PASTE (4 Steps)

### Step 0: Activate Environment (Do This First!)
```powershell
cd d:\Bunny\AGNI
.venv_models\Scripts\Activate.ps1
```

### Step 1: Train Model (2-3 hours on your laptop with batch-size 32)
```powershell
python Models/improved_train_enhanced.py --model enhanced --epochs 30 --batch-size 32
```
**Output:** `Models/checkpoints/enhanced_best.pth` | **F1:** 50-65%

**Your Laptop Specs:**
- CPU: Intel Core i7-1165G7 (4 cores, 8 threads)
- RAM: 40 GB (excellent!)
- GPU: Intel Iris Xe Graphics (not ideal for training)
- Recommended batch size: **32** (2√ó faster than 16)
- Training time: **2-3 hours** (vs 6-7 with batch 16)

### Step 2: Test Detection (10 seconds)
```powershell
python Models/predict_enhanced.py --model enhanced --input datasets/clips/stuttering-clips/clips/FluencyBank_010_0.wav --output test_result.json
```
**Output:** `test_result.json` (stuttering %, classes)

### Step 3: Get Repaired Audio (10 seconds)
```powershell
python Models/run_asr_map_repair.py --model_path Models/checkpoints/enhanced_best.pth --input_file datasets/clips/stuttering-clips/clips/FluencyBank_010_0.wav --output_audio output/repaired_audio/FluencyBank_010_0_repaired.wav --mode attenuate
```
**Output:** 
- `output/repaired_audio/FluencyBank_010_0_repaired.wav` ‚Üê **LISTEN HERE** üéµ
- `output/diagnostics/FluencyBank_010_0.asr_repair.json` ‚Üê Report

---

## üìã SCRIPTS EXPLAINED - What To Run & When

### ‚≠ê MAIN SCRIPTS (3 Total - This is All You Need)

**1. improved_train_enhanced.py** (TRAINING - Run First)
- Purpose: Train the stuttering detection model
- When: Only once at the beginning
- Features: Class weighting, mixed precision, early stopping
- Command (Recommended): `python Models/improved_train_enhanced.py --model enhanced --epochs 30 --batch-size 32`
- Alt Command (Faster): `python Models/improved_train_enhanced.py --model enhanced --epochs 30 --batch-size 64`
- Alt Command (Slower): `python Models/improved_train_enhanced.py --model enhanced --epochs 30 --batch-size 16`
- Output: `Models/checkpoints/enhanced_best.pth` (~3.4 MB)
- Time: **2-3 hours (batch-32, i7-1165G7)** | 6-7 hours (batch-16) | 1.5-2 hours (batch-64)
- Device: CPU (Intel Iris Xe GPU not recommended for this task)

**2. predict_enhanced.py** (TESTING - After Training)
- Purpose: Test detection on audio files
- When: After training to verify model works
- Supports: Single file or batch processing
- Command: `python Models/predict_enhanced.py --model enhanced --input audio.wav`
- Output: JSON with stuttering %, detected classes, confidence
- Time: < 10 seconds per file

**3. run_asr_map_repair.py** (FULL PIPELINE - To Get Repaired Audio)
- Purpose: Complete end-to-end workflow (detect ‚Üí transcribe ‚Üí map ‚Üí repair)
- When: When you want final repaired audio
- Modes: remove, silence, attenuate
- Command: `python Models/run_asr_map_repair.py --model_path best.pth --input_file audio.wav --output_audio output.wav`
- Output: Repaired WAV + JSON diagnostics
- Time: 5-10 seconds per file

### üîß SUPPORT SCRIPTS (8 Total - All Required)

Required for the 3 main scripts to work:

| Script | Used By | Purpose | Size |
|--------|---------|---------|------|
| model_enhanced.py | Training | Enhanced model (7 layers, attention, residual) | 7.3 KB |
| model_cnn.py | Training/Testing | SimpleCNN baseline (4 layers) | 2.3 KB |
| features.py | All | Log-Mel spectrogram extraction | 3.1 KB |
| asr_whisper.py | Repair | Speech-to-text transcription | 8.3 KB |
| repair.py | Repair | Audio editing engine | 9.5 KB |
| map_sed_words.py | Repair | Window-to-word alignment | 1.9 KB |
| utils.py | All | Helper functions | 4.9 KB |
| __init__.py | All | Package init | 0.4 KB |

---

## üóëÔ∏è WASTE SCRIPTS - Safe To Delete

### ‚ùå DELETE THIS (Definite Waste)

**improved_train.py** (388 lines, 13 KB)
- **Problem:** Redundant old training script
- **Why waste:** `improved_train_enhanced.py` is better (newer, more features)
- **Recommendation:** DELETE immediately
- **Command:** `Remove-Item -Path "d:\Bunny\AGNI\Models\improved_train.py"`
- **Impact:** -13 KB, cleaner codebase, no confusion

### ‚ö†Ô∏è KEEP THIS (Optional, Not Waste)

**ctc_align.py** (202 lines, 9 KB)
- **Purpose:** Advanced character-level alignment (optional)
- **Use:** Only if you need ultra-precise word boundaries
- **Current:** Using Whisper + energy refinement (sufficient)
- **Recommendation:** KEEP (might need for production)
- **Cost:** Only 9 KB

---

## ‚öôÔ∏è HOW THE PIPELINE WORKS

```
Audio File (WAV/MP3)
        ‚Üì
[STEP 1] DETECTION (Sliding-Window CNN)
  - Scan with 1.0s windows, 0.5s hop
  - Classify: Prolongation, Block, Sound Rep, Word Rep, Interjection
        ‚Üì
[STEP 2] TRANSCRIPTION (Whisper ASR)
  - Convert speech to text
  - Generate word-level timestamps
        ‚Üì
[STEP 3] MAPPING (Window-to-Word Alignment)
  - Link detected stutter frames to specific words
  - Create per-word stutter labels
        ‚Üì
[STEP 4] REPAIR (Audio Editing)
  - Remove: Excise stuttered words
  - Silence: Replace with quiet
  - Attenuate: Reduce volume (-10dB) ‚Üê DEFAULT
        ‚Üì
FINAL OUTPUT
  ‚îú‚îÄ Repaired Audio (WAV file) ‚úÖ
  ‚îî‚îÄ Diagnostics (JSON report)
```

---

## üéØ EXECUTION ORDER & TIME

### ONE-TIME SETUP (on your laptop: i7-1165G7, 40GB RAM)
```
1. Activate environment           < 1 second
2. Preprocess data               ~2 minutes
3. Train model (30 epochs)       2-3 hours    ‚Üê LONG WAIT (with batch-size 32)
4. Done! Ready to use
```

### REPEATED USAGE (After Model Trained)
```
1. Activate environment           < 1 second
2. Run predict/repair             10-20 seconds
3. Get results
```

### TYPICAL WORKFLOW
```
.venv_models\Scripts\Activate.ps1                              # 1 second
python Models/improved_train_enhanced.py --model enhanced --epochs 30 --batch-size 32  # 2-3 HOURS (train once)
python Models/predict_enhanced.py --model enhanced --input ...  # 10 seconds (test)
python Models/run_asr_map_repair.py --model_path ... --input ... # 10 seconds (repair)
Open output/repaired_audio/*.wav in audio player  # Listen!
```

### BATCH SIZE OPTIONS

**Your Laptop Specs:** Intel i7-1165G7 (4 cores) + 40GB RAM

| Batch Size | Speed | RAM Usage | Training Time | Notes |
|-----------|-------|-----------|----------------|-------|
| 16 | Slow | ~10 GB | 6-7 hours | Safe, but slow |
| **32** | **Fast** | **~18 GB** | **2-3 hours** | ‚≠ê **RECOMMENDED** |
| 64 | Very Fast | ~32 GB | 1.5-2 hours | Max speed, uses 80% RAM |

**Recommendation:** Use `--batch-size 32` for best balance ‚úÖ

---

## üìä REPAIR MODES (Choose One)

```powershell
--mode attenuate    ‚Üê RECOMMENDED (Most Natural)
  Effect: Reduce stuttered word volume by 10dB
  Sound: Natural, preserves context
  Use: Default, safest choice
  Example: "I c-c-c-can't" ‚Üí "I [quieter] can't"
  
--mode silence      (Alternative)
  Effect: Replace with silence
  Sound: Clear but may sound choppy
  Use: When obvious removal needed
  Example: "I c-c-c-can't" ‚Üí "I [pause] can't"
  
--mode remove       (Aggressive)
  Effect: Excise words, stitch audio
  Sound: Very choppy, unnatural gaps
  Use: Only for complete removal
  Example: "I c-c-c-can't" ‚Üí "I can't"
```

---

## üìÅ FILE STRUCTURE

```
d:\Bunny\AGNI\
‚îÇ
‚îú‚îÄ‚îÄ README.md ‚Üê YOU ARE HERE
‚îÇ
‚îú‚îÄ‚îÄ Models/
‚îÇ   ‚îú‚îÄ‚îÄ improved_train_enhanced.py ‚≠ê TRAINING
‚îÇ   ‚îú‚îÄ‚îÄ predict_enhanced.py ‚≠ê TESTING
‚îÇ   ‚îú‚îÄ‚îÄ run_asr_map_repair.py ‚≠ê REPAIR+PIPELINE
‚îÇ   ‚îú‚îÄ‚îÄ preprocess_data.py (data preprocessing)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ model_enhanced.py, model_cnn.py (REQUIRED)
‚îÇ   ‚îú‚îÄ‚îÄ features.py, asr_whisper.py (REQUIRED)
‚îÇ   ‚îú‚îÄ‚îÄ repair.py, map_sed_words.py (REQUIRED)
‚îÇ   ‚îú‚îÄ‚îÄ utils.py, __init__.py (REQUIRED)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ improved_train.py üóëÔ∏è DELETE
‚îÇ   ‚îú‚îÄ‚îÄ ctc_align.py ‚ö†Ô∏è OPTIONAL
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ checkpoints/
‚îÇ       ‚îî‚îÄ‚îÄ enhanced_best.pth (created after training)
‚îÇ
‚îú‚îÄ‚îÄ datasets/
‚îÇ   ‚îú‚îÄ‚îÄ clips/stuttering-clips/clips/ (30,036 processed audio files)
‚îÇ   ‚îú‚îÄ‚îÄ SEP-28k_labels.csv, fluencybank_labels.csv
‚îÇ   ‚îú‚îÄ‚îÄ features/train/ (extracted spectrograms for training)
‚îÇ   ‚îú‚îÄ‚îÄ features/val/ (extracted spectrograms for validation)
‚îÇ   ‚îî‚îÄ‚îÄ annotated_time_aligned/
‚îÇ
‚îî‚îÄ‚îÄ output/
    ‚îú‚îÄ‚îÄ repaired_audio/ ‚Üê FINAL AUDIO FILES ‚úÖ
    ‚îú‚îÄ‚îÄ diagnostics/ (JSON reports)
    ‚îú‚îÄ‚îÄ metrics/ (training metrics)
    ‚îî‚îÄ‚îÄ test_results/ (batch results)
```

---

## ‚è±Ô∏è TIME BREAKDOWN

**For your laptop (i7-1165G7, 4 cores, 40GB RAM):**

| Operation | Batch 16 | Batch 32 | Batch 64 |
|-----------|----------|----------|----------|
| Activate env | <1s | <1s | <1s |
| Preprocess data | ~2 min | ~2 min | ~2 min |
| Train 30 epochs | 6-7 hrs | **2-3 hrs** ‚≠ê | 1.5-2 hrs |
| Test 1 file | <10s | <10s | <10s |
| Repair 1 file | 5-10s | 5-10s | 5-10s |
| Batch 100 files | 8-15m | 8-15m | 8-15m |

---

## ‚úÖ EXPECTED RESULTS

### Training (30 epochs on i7-1165G7 with batch-size 32)
- ‚úÖ Time: 2-3 hours
- ‚úÖ Best Model Epoch: ~15-20
- ‚úÖ Final F1: 50-65%
- ‚úÖ Early Stop: ~22-28 epochs
- ‚úÖ RAM Used: ~18 GB (safe on 40GB system)

### Inference
- ‚úÖ Accuracy: 50-85% F1
- ‚úÖ Speed: 1-5s per 10s clip (CPU)
- ‚úÖ Quality: No artifacts
- ‚úÖ Coverage: 60-80% of stuttering

---

## üõ†Ô∏è TROUBLESHOOTING

### Training is slow
```powershell
# Increase batch size (your laptop has 40GB RAM - use it!)
--batch-size 32  # 2√ó faster
--batch-size 64  # 3√ó faster (if you want maximum speed)

# Or use SimpleCNN (smaller model)
--model simple

# Or reduce epochs for testing
--epochs 5
```

### High RAM usage
```powershell
# Reduce batch size
--batch-size 16
--batch-size 8
```

### CUDA out of memory (if using GPU)
```powershell
# Reduce batch size
--batch-size 8

# Or use CPU instead
(don't add --gpu flag)
```

### Model not found
```powershell
# Run training first
python Models/improved_train_enhanced.py --model enhanced --epochs 30 --batch-size 32
```

### Low accuracy (F1 < 40%)
- Increase training epochs (try 50+)
- Increase batch size (try 32 or 64)
- Check data quality in datasets/
- Adjust detection threshold

### Audio sounds unnatural
```powershell
# Try attenuate mode (recommended)
--mode attenuate

# Or try silence
--mode silence
```

### Preprocessing data
```powershell
# If you need to re-extract features from raw audio
python Models/preprocess_data.py
# Outputs: datasets/features/train/ and datasets/features/val/
```

---

## ÔøΩ YOUR LAPTOP SPECS & RECOMMENDATIONS

**Current System:**
- CPU: Intel Core i7-1165G7 (4 cores, 8 threads @ 2.80 GHz)
- RAM: 40 GB total (~21 GB available)
- GPU: Intel Iris Xe Graphics (2 GB VRAM)
- Storage: Used for datasets/features + model checkpoints

**Performance Recommendations:**

‚úÖ **Training:**
- Use CPU (Intel Iris Xe not efficient for training)
- Batch size: **32** (recommended for 2-3 hour training)
- No GPU flag needed
- Training time: 2-3 hours for 30 epochs

‚úÖ **Inference (Prediction & Repair):**
- Much faster (10-20 seconds per file)
- Runs on CPU fine
- No GPU acceleration needed

‚ö†Ô∏è **GPU Not Recommended:**
- Intel Iris Xe is integrated GPU
- PyTorch on Iris Xe has poor support
- CPU training faster on 4-core i7
- Stick with CPU-only training

**Memory Management:**
- Batch 16: ~10 GB RAM usage
- Batch 32: ~18 GB RAM usage ‚Üê **Recommended**
- Batch 64: ~32 GB RAM usage (safe headroom)

---

## üìö DATASET INFO

- **Total Clips:** 32,321 audio files (30,036 processed)
- **SEP-28k:** 28,177 labeled clips
- **FluencyBank:** 4,144 labeled clips
- **Classes:** 5 stutter types (Prolongation, Block, Sound Rep, Word Rep, Interjection)
- **Format:** Multi-label (clips can have multiple types)
- **Audio:** 16 kHz baseline, diverse speakers/accents
- **Location:** `datasets/clips/stuttering-clips/clips/`

---

## üéØ COMMAND REFERENCE (Copy & Paste Fast Access)

```powershell
# Activate (always first)
.venv_models\Scripts\Activate.ps1

# Preprocess data (if needed)
python Models/preprocess_data.py

# Train (with your laptop specs - batch 32 for 2-3 hours)
python Models/improved_train_enhanced.py --model enhanced --epochs 30 --batch-size 32

# Or faster (batch 64 - 1.5-2 hours)
python Models/improved_train_enhanced.py --model enhanced --epochs 30 --batch-size 64

# Test detection
python Models/predict_enhanced.py --model enhanced --input "datasets/clips/stuttering-clips/clips/FluencyBank_010_0.wav" --output test.json

# Repair single file
python Models/run_asr_map_repair.py --model_path Models/checkpoints/enhanced_best.pth --input_file "datasets/clips/stuttering-clips/clips/FluencyBank_010_0.wav" --output_audio output/repaired_audio/output.wav --mode attenuate

# Batch test
python Models/predict_enhanced.py --model enhanced --batch-dir "datasets/clips/stuttering-clips/clips/" --output-dir output/test_results/
```

---

## ‚ú® SUMMARY

‚úÖ **3 scripts only:** improved_train_enhanced.py, predict_enhanced.py, run_asr_map_repair.py  
‚úÖ **1 waste script:** improved_train.py (safe to delete)  
‚úÖ **Execution order:** Train ‚Üí Test ‚Üí Repair  
‚úÖ **Time:** 2-3 hours total on your laptop (with batch-size 32)  
‚úÖ **Output:** Repaired audio in output/repaired_audio/  
‚úÖ **Datasets:** 30,036 processed samples ready  
‚úÖ **Everything ready** to start using!

**Your Laptop (i7-1165G7, 40GB RAM):**
- ‚≠ê Use batch-size 32 for optimal 2-3 hour training
- ‚≠ê CPU-only training (GPU not worth it)
- üìä 30,000+ training samples
- üéØ Expected F1: 50-65%

**üëâ Next step: Run training with batch-size 32! üöÄ**

```powershell
python Models/improved_train_enhanced.py --model enhanced --epochs 30 --batch-size 32
```
