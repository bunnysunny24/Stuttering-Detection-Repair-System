# ============================================================================
# STUTTERING DETECTION & REPAIR SYSTEM - COMPLETE REQUIREMENTS
# ============================================================================
# 
# SETUP OPTIONS:
# 
# 1. CPU ONLY (Recommended for ThinkPad T14 Gen 2i with i7):
#    python -m venv .venv_models
#    .venv_models\Scripts\Activate.ps1
#    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
#    pip install -r requirements_complete.txt
#
# 2. NVIDIA GPU (CUDA 11.8 - RTX 3000/4000 series):
#    python -m venv .venv_models
#    .venv_models\Scripts\Activate.ps1
#    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
#    pip install -r requirements_complete.txt
#
# 3. NVIDIA GPU (CUDA 12.1 - RTX 4090/RTX 5000/Latest):
#    python -m venv .venv_models
#    .venv_models\Scripts\Activate.ps1
#    pip install torch torchvision torchaudio
#    pip install -r requirements_complete.txt
#
# 4. AMD GPU (ROCm 5.7 - Radeon RX 6000/7000):
#    python -m venv .venv_models
#    .venv_models\Scripts\Activate.ps1
#    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7
#    pip install -r requirements_complete.txt
#
# 5. APPLE SILICON (M1/M2/M3 Mac):
#    python -m venv .venv_models
#    source .venv_models/bin/activate
#    pip install torch torchvision torchaudio
#    pip install -r requirements_complete.txt
#
# ============================================================================

# ────────────────────────────────────────────────────────────────────────
# PYTORCH FRAMEWORK (CHOOSE ONE INSTALLATION METHOD ABOVE!)
# ────────────────────────────────────────────────────────────────────────
# 
# PyTorch versions available:
# ✅ CPU-only:     150 MB, uses all CPU cores
# ✅ CUDA 11.8:    2.5 GB, for NVIDIA cards (RTX 3060, 3070, 3080, A100)
# ✅ CUDA 12.1:    2.5 GB, for NVIDIA cards (RTX 4090, RTX 5000, H100)
# ✅ ROCm 5.7:     2.5 GB, for AMD Radeon (RX 6700, 6800, 7900)
# ✅ MPS:          150 MB, for Apple Silicon (M1, M2, M3)
#
# DO NOT: pip install torch from requirements.txt on first install
# Instead: Follow steps above to install PyTorch first, then requirements.txt
#
# Why: PyTorch needs special PyPI index URLs for GPU versions

torch>=1.13.0              # PyTorch - Core ML framework
                           # CPU: ~150 MB, fast compilation
                           # GPU: ~2.5 GB, GPU-accelerated training
torchvision>=0.14.0        # Image transforms, datasets, models
torchaudio>=0.13.0         # Audio processing, features, visualization

# ────────────────────────────────────────────────────────────────────────
# NEURAL NETWORK ARCHITECTURES & TRANSFORMERS
# ────────────────────────────────────────────────────────────────────────

transformers>=4.30.0       # HuggingFace transformer models
                           # Includes: BERT, Wav2Vec2, Whisper, ELECTRA
                           # Used for: Advanced speech models, fine-tuning
peft>=0.4.0               # Parameter-Efficient Fine-Tuning
                           # Methods: LoRA, prefix tuning, adapters
                           # Use: Reduce memory for fine-tuning large models
accelerate>=0.21.0        # Multi-GPU & mixed precision training
                           # Handles: Distributed training, gradient accumulation
                           # Needed: For training on multiple GPUs

# ────────────────────────────────────────────────────────────────────────
# AUDIO PROCESSING (CRITICAL FOR STUTTERING DETECTION)
# ────────────────────────────────────────────────────────────────────────

librosa>=0.9.2            # Audio analysis library
                           # Features: Spectrograms, MFCC, chromagrams
                           # Used: Extracting audio features for ML
soundfile>=0.12.1         # Audio file I/O
                           # Formats: WAV, FLAC, OGG, RAW
                           # CRITICAL: Must be version 0.12.1+
                           # Fix: pip install soundfile==0.12.1
openai-whisper>=20250625  # Speech-to-text transcription
                           # Models: tiny (39MB), base, small (466MB), medium, large
                           # Use: Convert audio to text for word-level alignment
                           # Download: Automatic on first use (~1.4GB for small)

# FASTER ALTERNATIVE (if Whisper is slow on CPU):
faster-whisper>=0.10.0   # CTranslate2-based Whisper
#                           # Speed: 2-4x faster than original Whisper
#                           # Install with: pip install faster-whisper
#                           # Replace: import whisper -> from faster_whisper import WhisperModel

# ────────────────────────────────────────────────────────────────────────
# DATA PROCESSING & NUMERICAL COMPUTING
# ────────────────────────────────────────────────────────────────────────

numpy>=1.24.0             # Numerical computing
                           # Used: Arrays, matrix operations, broadcasting
scipy>=1.10.0             # Scientific computing
                           # Used: Interpolation, signal processing, statistics
pandas>=1.5.0             # Data tables and manipulation
                           # Used: Reading CSV labels, data management
scikit-learn>=1.2.0       # Machine learning utilities
                           # Used: Metrics (F1, precision, recall), preprocessing

# ────────────────────────────────────────────────────────────────────────
# PROGRESS BARS & TERMINAL UI
# ────────────────────────────────────────────────────────────────────────

tqdm>=4.65.0              # Progress bars
                           # Shows: Training progress, batch processing
                           # Clean output with ETA estimates

# ────────────────────────────────────────────────────────────────────────
# VISUALIZATION & DIAGNOSTICS
# ────────────────────────────────────────────────────────────────────────

matplotlib>=3.7.0         # Plotting and visualization
                           # Used: Spectrograms, training curves, diagnostics
                           # Output: PNG files for analysis

# ────────────────────────────────────────────────────────────────────────
# SPEECH PROCESSING & ALIGNMENT
# ────────────────────────────────────────────────────────────────────────

jiwer>=2.4.0              # Word Error Rate (WER) calculation
                           # Used: Evaluating ASR quality
ctc-segmentation>=1.6.0   # CTC-based forced alignment
                           # Aligns: Speech to text with timing
                           # Use: Precise word-level boundary detection

# ────────────────────────────────────────────────────────────────────────
# TOKENIZATION (Required for Transformers)
# ────────────────────────────────────────────────────────────────────────

sentencepiece>=0.1.98     # Subword tokenization
                           # Models: SentencePiece, WordPiece
                           # Used: Splitting text for BERT, Wav2Vec
tokenizers>=0.13.3        # Fast tokenizers from HuggingFace
                           # Language: Multiple language support
                           # Speed: Vectorized Rust implementation

# ────────────────────────────────────────────────────────────────────────
# WEB API (OPTIONAL - for REST API serving)
# ────────────────────────────────────────────────────────────────────────

fastapi>=0.95.0           # Modern async web framework
                           # Used: Create /detect and /repair endpoints
                           # Features: Request validation, auto docs
uvicorn[standard]>=0.22.0 # ASGI web server
                           # Serves: FastAPI apps with high concurrency
python-multipart>=0.0.6   # Multipart form data parsing
                           # Handles: File uploads in APIs

# ────────────────────────────────────────────────────────────────────────
# TESTING & QUALITY ASSURANCE
# ────────────────────────────────────────────────────────────────────────

pytest>=7.2.0             # Testing framework
                           # Used: Unit tests, integration tests

# ════════════════════════════════════════════════════════════════════════
# HARDWARE REQUIREMENTS & RECOMMENDATIONS
# ════════════════════════════════════════════════════════════════════════
#
# MINIMUM REQUIREMENTS:
#   CPU:      Intel i5 / AMD Ryzen 5 (4 cores)
#   RAM:      8 GB
#   Storage:  20 GB SSD
#   GPU:      None (optional but recommended for training)
#
# RECOMMENDED (Your ThinkPad T14 Gen 2i):
#   CPU:      Intel Core i7-1165G7 ✅ (4 cores, 8 threads - good!)
#   RAM:      40 GB ✅ (excellent, allows batch-96)
#   Storage:  50+ GB SSD ✅ (for models and datasets)
#   GPU:      Not recommended (Iris Xe slower than CPU)
#
# FOR PRODUCTION/FAST TRAINING:
#   CPU:      Intel Xeon / AMD EPYC (16+ cores)
#   RAM:      128+ GB
#   Storage:  1 TB NVMe SSD
#   GPU:      NVIDIA H100 (80GB VRAM), RTX 6000 Ada (48GB), or similar
#   Network:  2+ Gbps for distributed training
#
# GPU-SPECIFIC REQUIREMENTS:
#
# NVIDIA CUDA 11.8 (RECOMMENDED for RTX 3060/3070/3080/A100):
#   VRAM:        6GB+ (for batch-64)
#   Driver:      Version 520.06 or newer
#   CUDA Toolkit: 11.8 (automatic with PyTorch)
#   cuDNN:       8.6+ (automatic)
#
# NVIDIA CUDA 12.1 (For RTX 4090/5000/H100):
#   VRAM:        8GB+ (for batch-96)
#   Driver:      Version 525.105 or newer
#   CUDA Toolkit: 12.1 (automatic with PyTorch)
#   cuDNN:       8.9+ (automatic)
#
# AMD ROCm 5.7 (For Radeon RX 6000/7000):
#   VRAM:        8GB+ (RX 6800 XT, 6900 XT)
#   Driver:      AMDGPU IOMMU disabled
#   ROCm:        5.7.3+
#   Kernel:      Linux 5.4+ (Windows support via WSL2)
#
# APPLE SILICON (M1/M2/M3):
#   Unified Memory: 16GB+ (effective GPU VRAM)
#   Training speed: Faster than Intel CPU, slower than NVIDIA
#   Automatic:     No setup needed, Metal GPU (mps) automatic
#
# ════════════════════════════════════════════════════════════════════════
# ESTIMATED TRAINING TIMES (30 epochs)
# ════════════════════════════════════════════════════════════════════════
#
# Your ThinkPad T14 (i7-1165G7, 40GB RAM, CPU-only, batch-96):
#   Total: ~17 hours (35 min/epoch)
#   Per epoch: ~35 minutes
#   Good for: Overnight training
#
# With NVIDIA RTX 4090 (batch-96):
#   Total: ~1.5 hours (3 min/epoch)
#   Per epoch: ~3 minutes
#   Speedup: 11x faster than your CPU!
#
# With NVIDIA A100 (batch-256):
#   Total: ~45 minutes (1.5 min/epoch)
#   Per epoch: ~1.5 minutes
#   Speedup: 23x faster than your CPU!
#
# With AMD Radeon RX 6900 XT (batch-96):
#   Total: ~4 hours (8 min/epoch)
#   Per epoch: ~8 minutes
#   Speedup: 4x faster than your CPU
#
# ════════════════════════════════════════════════════════════════════════
# BATCH SIZE RECOMMENDATIONS (Your ThinkPad T14, 40GB RAM, CPU)
# ════════════════════════════════════════════════════════════════════════
#
# Batch-32:  ~10 GB RAM, ~55 min/epoch | SLOWEST
# Batch-64:  ~19 GB RAM, ~40 min/epoch | BALANCED ⭐ recommended for many laptops
# Batch-96:  ~28 GB RAM, ~35 min/epoch | FASTEST ⭐ recommended for you (40GB available)
# Batch-128: ~36 GB RAM, ~33 min/epoch | Too risky (only 4GB headroom left)
#
# For your 40GB laptop:
# - Use batch-96 for best speed
# - If system slows down, reduce to batch-64
# - Batch-32 only if you run out of memory
#
# ════════════════════════════════════════════════════════════════════════
# STEP-BY-STEP INSTALLATION & VERIFICATION
# ════════════════════════════════════════════════════════════════════════
#
# STEP 1: Create virtual environment (first time only)
# ───────────────────────────────────────────────
# cd d:\Bunny\AGNI
# python -m venv .venv_models
#
# STEP 2: Activate environment (every time you start)
# ─────────────────────────────────────────────────
# .venv_models\Scripts\Activate.ps1
# # You should see: (.venv_models) PS D:\Bunny\AGNI>
#
# STEP 3: Upgrade pip (important!)
# ─────────────────────────────────
# python -m pip install --upgrade pip
#
# STEP 4: Install PyTorch (choose ONE based on your hardware)
# ────────────────────────────────────────────────────────────
#
# FOR YOUR THINKPAD (CPU-only, fastest & recommended):
# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
#
# FOR NVIDIA RTX 3000/4000 (CUDA 11.8):
# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
#
# FOR NVIDIA RTX 4090/5000 (CUDA 12.1, latest):
# pip install torch torchvision torchaudio
#
# FOR AMD RADEON (ROCm 5.7):
# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7
#
# FOR APPLE SILICON:
# pip install torch torchvision torchaudio
#
# STEP 5: Install remaining dependencies from this file
# ──────────────────────────────────────────────────────
# pip install -r requirements_complete.txt
#
# STEP 6: Verify everything works
# ────────────────────────────────
# python -c "
# import torch
# import librosa
# import whisper
# print(f'PyTorch: {torch.__version__}')
# print(f'CUDA available: {torch.cuda.is_available()}')
# if torch.cuda.is_available():
#     print(f'GPU: {torch.cuda.get_device_name(0)}')
#     print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')
# print('✅ All libraries installed!')
# "
#
# Expected output:
# PyTorch: 2.0.1
# CUDA available: False (CPU) or True (GPU)
# GPU: (not shown for CPU, or shows GPU name)
# ✅ All libraries installed!
#
# ════════════════════════════════════════════════════════════════════════
# TROUBLESHOOTING COMMON ISSUES
# ════════════════════════════════════════════════════════════════════════
#
# ISSUE: "No module named 'torch'"
# CAUSE:  Environment not activated or PyTorch not installed
# FIX:    .venv_models\Scripts\Activate.ps1
#         pip install torch...  (see STEP 4 above)
#
# ISSUE: "CUDA out of memory" during training
# CAUSE:  Batch size too large
# FIX:    reduce --batch-size from 96 to 64 or 32
#         Example: python Models/improved_train_enhanced.py --epochs 30 --batch-size 64
#
# ISSUE: "soundfile not found" error
# CAUSE:  Wrong version installed
# FIX:    pip uninstall soundfile -y
#         pip install soundfile==0.12.1
#
# ISSUE: "cannot be loaded because running scripts is disabled"
# CAUSE:  PowerShell execution policy
# FIX:    Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
#         Then: .venv_models\Scripts\Activate.ps1
#
# ISSUE: Whisper downloads 1.4GB on first run
# CAUSE:  Whisper model downloaded on first execution
# FIX:    Normal! Pre-download to speed up: python -c "import whisper; whisper.load_model('small')"
#
# ISSUE: Training very slow on CPU
# CAUSE:  CPU-only training is inherently slower
# FIX:    Consider GPU upgrade, or reduce batch size for faster epochs
#
# ════════════════════════════════════════════════════════════════════════
